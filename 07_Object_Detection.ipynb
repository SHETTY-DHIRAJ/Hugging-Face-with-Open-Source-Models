{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1f86a0",
   "metadata": {
    "id": "BNm6JThea320"
   },
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40889c1c",
   "metadata": {},
   "source": [
    "- Install the following:\n",
    "\n",
    "```\n",
    "    !pip install transformers\n",
    "    !pip install gradio\n",
    "    !pip install timm\n",
    "    !pip install inflect\n",
    "    !pip install phonemizer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5691a3",
   "metadata": {},
   "source": [
    "**Note:**  `py-espeak-ng` is only available Linux operating systems.\n",
    "\n",
    "To run locally in a Linux machine, follow these commands:\n",
    "```\n",
    "    sudo apt-get update\n",
    "    sudo apt-get install espeak-ng\n",
    "    pip install py-espeak-ng\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49162d95",
   "metadata": {
    "id": "kkkJorDBd8oY"
   },
   "source": [
    "### Build the `object-detection` pipeline using ðŸ¤— Transformers Library\n",
    "\n",
    "- This model was release with the paper [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872) from Carion et al. (2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d655cdd",
   "metadata": {
    "height": 30,
    "id": "BwlBLWY5dLhB"
   },
   "outputs": [],
   "source": [
    "from helper import load_image_from_url, render_results_in_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca03dc1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82277f15",
   "metadata": {},
   "source": [
    "- Here is some code that suppresses warning messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490a45fd",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from helper import ignore_warnings\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd89c176",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "od_pipe = pipeline(\"object-detection\", \"./models/facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112beaaa",
   "metadata": {},
   "source": [
    "Info about [facebook/detr-resnet-50](https://huggingface.co/facebook/detr-resnet-50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea8aef5",
   "metadata": {},
   "source": [
    "Explore more of the [Hugging Face Hub for more object detection models](https://huggingface.co/models?pipeline_tag=object-detection&sort=trending)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb14a49",
   "metadata": {},
   "source": [
    "### Use the Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025ac81",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391,
     "referenced_widgets": [
      "7978d52d2e0247189ff62b5f03a07255",
      "d09488557e204ab082d9e737181ed034",
      "c3a6dcba63ae4d55ae55a79bd6849f05",
      "20c1146b99e64cccb95f015f18aebb2c",
      "0747d89099364a22b089f6600df6515a",
      "f701db0a2b5443938ebef1b1c383d930",
      "ad6ac2565c4f4338a4a8200c95148753",
      "1bdfd1aa1f3b47a5b50740dbe9108416",
      "05a17f14f1ec4018b13286761bc6140f",
      "20092ac47a794151aa0a324df76c80f7",
      "7bbf39a730f147b1875ba952c34b8ed5",
      "e31526c5288344a7a34404f3d237ee2b",
      "e445744a2c724f7b92f20b11c299aa33",
      "86dc5c1797204ff086a892b7458825a7",
      "311bd5df491447178d80efd07140deb1",
      "518e75567a79481eb3d1bdd2dd022212",
      "43d68a32193f47e19e41918189dee22a",
      "202a8e5017ad43d286dec7c9453857e1",
      "8a1cdd27284c4d5f87cc87e14d438cc0",
      "935a5464b920485c8941ff3d93e2c185",
      "d9a1e78d3ea44343bb8e15c768421540",
      "a4895ef524b04edd9523eb323b51b1e8",
      "de905191365243cfab8e04d8845ec797",
      "5871cb766d244506841d2b3899349346",
      "e092e341c7ca4168baf60a25514ac57e",
      "bcac20c050e34bc1a875b005d0f029c8",
      "86f6a4da1ee3481abfaaafe0c1b5bad8",
      "fb1c4da5a415471595d3ea0fee505a45",
      "a3fe7b7089f542abb40203ae635c695d",
      "67f88f95edb5408785639fbc92e2c3d9",
      "1c674ddbf01440028edb634f7dbfb2ef",
      "468ce2d389184f87bb47a0ab93e8cbf7",
      "8db974a8664044a091fa696f5bf66e77",
      "87fab1dbc0ae40a285d44b8e1d2ea024",
      "1beb4e6b36304d2d990aa4750b2e8f73",
      "44b430e61b03475d95d8480d2b126cd3",
      "385dc6f1834449f18dc87760ed9fa6d1",
      "4874f2fae5d145699a66ee9e0ded3051",
      "6a024b3605914ea3bd7f366d678603b7",
      "921cd39a80ce4e9281a180e175e381c1",
      "5b3b3d3ea7ee4f5b8c7d46644ac024c7",
      "10535ccdbe114df6bb0e41d80c149d20",
      "98848407973241e18b826e0f3e31123c",
      "d685478810a848a3b13bd745961189c4"
     ]
    },
    "height": 30,
    "id": "yHWwzv3qemBi",
    "outputId": "38fc2acf-b935-4698-e154-64aef6d651a7"
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471cf9b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "raw_image = Image.open('') # Give the reference of the image file you want to use.\n",
    "raw_image.resize((569, 491))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3cc0b3",
   "metadata": {
    "height": 30,
    "id": "7fcJtShhfkf1"
   },
   "outputs": [],
   "source": [
    "pipeline_output = od_pipe(raw_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3241f1",
   "metadata": {},
   "source": [
    "- Return the results from the pipeline using the helper function `render_results_in_image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc27d8d",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "processed_image = render_results_in_image(\n",
    "    raw_image, \n",
    "    pipeline_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c012ca",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "processed_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3677ece2",
   "metadata": {},
   "source": [
    "### Using `Gradio` as a Simple Interface\n",
    "\n",
    "- Use [Gradio](https://www.gradio.app) to create a demo for the object detection app.\n",
    "- The demo makes it look friendly and easy to use.\n",
    "- You can share the demo with your friends and colleagues as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b6d3b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476ebdb0",
   "metadata": {
    "height": 132,
    "id": "HPfWT6d8mTEL"
   },
   "outputs": [],
   "source": [
    "def get_pipeline_prediction(pil_image):\n",
    "    \n",
    "    # First get the pipeline output for the given pil_image\n",
    "    pipeline_output = od_pipe(pil_image)\n",
    "\n",
    "    # Then process the image using the pipeline output\n",
    "    processed_image = render_results_in_image(pil_image,\n",
    "                                            pipeline_output)\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a3bf4",
   "metadata": {
    "height": 132,
    "id": "3onzDMlzl7uj"
   },
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "  fn=get_pipeline_prediction,\n",
    "  inputs=gr.Image(label=\"Input image\", \n",
    "                  type=\"pil\"),\n",
    "  outputs=gr.Image(label=\"Output image with predicted instances\",\n",
    "                   type=\"pil\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2276ab76",
   "metadata": {},
   "source": [
    "- `share=True` will provide an online link to access to the demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838d567",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "height": 30,
    "id": "QcE4p98UmGOc",
    "outputId": "fdf28840-e2c1-488c-da58-8dc605c6f42e"
   },
   "outputs": [],
   "source": [
    "demo.launch(share=True, server_port=int(os.environ['PORT1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78be7c2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cad2915",
   "metadata": {
    "height": 30
   },
   "source": [
    "### Close the app\n",
    "- Remember to call `.close()` on the Gradio app when you're done using it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9635a9",
   "metadata": {
    "id": "6LA1Wm6bl724"
   },
   "source": [
    "### Make an AI Powered Audio Assistant\n",
    "\n",
    "- Combine the object detector with a text-to-speech model that will help dictate what is inside the image.\n",
    "\n",
    "- Inspect the output of the object detection pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4536416",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pipeline_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29699180",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "od_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74f554",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from helper import summarize_predictions_natural_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de0e5ab",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "text = summarize_predictions_natural_language(pipeline_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af1094",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa032e77",
   "metadata": {},
   "source": [
    "### Generate Audio Narration of an Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ea3e6b",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "tts_pipe = pipeline(\"text-to-speech\",\n",
    "                    model=\"./models/kakao-enterprise/vits-ljs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d27ac1",
   "metadata": {},
   "source": [
    "More info about [kakao-enterprise/vits-ljs](https://huggingface.co/kakao-enterprise/vits-ljs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e2cd8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "narrated_text = tts_pipe(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa293b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284,
     "referenced_widgets": [
      "02c8da7c19e945c6b126cc9d1a9cde1c",
      "f35cd6e475b946dfaa75c607e19bce5e",
      "34c27cfda6be44a89ee39ddf3a2df540",
      "48b7aa27448c47b9b14250b2c42a9fa3",
      "2d128cd857e5440dad33c855a012b035",
      "66a4bde858f34d29a388c35428c35fe3",
      "ea500d795c61486db100416ba6992139",
      "9f22f318547a420ab078e742e65f9bd1",
      "a453054e3b5b429687329fbe270f557d",
      "baa1c7c610894119aafde921b82f7643",
      "3730a68cfc964336a635b1eb3a742e31",
      "0b6e5c370fcd43ddadb88a98e22bffd0",
      "e30d036f6a5841229538bed0e1bf5d97",
      "8909effa410d4d4faeadb56b41aefd5d",
      "12a74e65fe284f92a40418a05ad642b6",
      "66aa281ede8d43669d2c7c406d3c5d56",
      "742ba6b6a8584c81b10625038e631912",
      "45084206664b4979a70e7624b6f5d626",
      "5a2d20c7c00342c6812bb78ad6623161",
      "8f37058c0fe8474fb450795f1d2e5634",
      "f154bf741b11437b8dd2444189c9a25d",
      "a306dbc71ae84dc29d995a9a9ceaa580",
      "9cc867d7bbb146338b7d469118751bcc",
      "149bc68382624ab3b6a7a979b3b751cf",
      "0731a596dc6a43b4a939cee4be03a55d",
      "9b1bd6117a2c49a6877f2fd04dc40225",
      "40927e1dd8944889804e35e7142937dd",
      "f563a4e558c2447b821703df532ab512",
      "361cacd7377f457289fdbe3e9651ae6a",
      "ed091afe5c6749a18a3b742fca3d3757",
      "68e662024cf24cc2b192d64eb780915a",
      "5050fddbb01249c08ba5265bbcefc80f",
      "f892a9e557874920afbbeeb2f4cb07b9",
      "334bd6ab29ff4877be882204753a2dab",
      "f79b3126388a49e3b440e950209653d9",
      "6bbdec2ed932485b996ae63bce15d160",
      "5edb96689b70479faf1c724680d20681",
      "dba9d6bdeada4fbfa0032b30526544fe",
      "a82677a81c794b3abef26cef36f43d62",
      "bfa2b026aea74553b5e4a4beba8f6b17",
      "75dc8815d1284e71852d77d529065aba",
      "1fbb32d50e204f74acef47498849cf81",
      "4fe39d60cb9f455fa69082909f321187",
      "510e3d27bb114856af72081103ebeca4",
      "92e2fbc1f51c4dd9b667adafa567f653",
      "2aa7641a805642af9cf5f36b31396548",
      "75cc12c80c734242905a529b710ca4b3",
      "d5b6f479413c4699b2673235a5f9e8de",
      "1a4d4bfd56754fa6b25f16c39d7ee7f9",
      "0f4f2bc83a7f43c0a8d62160dc4b66b6",
      "c47d0b8edde648c3b324e656d155c70a",
      "3176a68d23e04e8b90e9aef2d158b00a",
      "80a41207a8e447a1a99e8bf108946b7a",
      "84df015bbed14f27be58c7eb42906f85",
      "9c2a0fef00124559a9c37d3a23841bdd"
     ]
    },
    "id": "A6EV19RCmK4i",
    "outputId": "a792cc08-39d4-47dc-96b5-f520386a9fec"
   },
   "source": [
    "### Play the Generated Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e62595",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPythonAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d28bfc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "height": 47,
    "id": "M-l4sMDaqUJM",
    "outputId": "a0bbdce2-216c-40c3-85da-2dd20d5676e8"
   },
   "outputs": [],
   "source": [
    "IPythonAudio(narrated_text[\"audio\"][0],\n",
    "             rate=narrated_text[\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8865d86",
   "metadata": {},
   "source": [
    "### Try it yourself! \n",
    "- Try these models with other images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93d8fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
